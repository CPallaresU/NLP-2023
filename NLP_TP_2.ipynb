{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "BuYbwms2mnkB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import urllib.request\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs\n",
        "import nltk\n",
        "# Descargar el diccionario\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import sys\n",
        "#import gradio as gr\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} -m pip install gradio --quiet"
      ],
      "metadata": {
        "id": "8_PieaU7r0DC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##OWN SIMILARITY"
      ],
      "metadata": {
        "id": "6-yeouNOuCAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"
      ],
      "metadata": {
        "id": "LKPeSH22sINd"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding (corpus):\n",
        "\n",
        "    words_set = {}\n",
        "    words_set = set(words_set)\n",
        "\n",
        "    for k in corpus:\n",
        "\n",
        "        words = set(k.split(\" \"))\n",
        "\n",
        "        for i in words :\n",
        "\n",
        "            words_set.add(i)\n",
        "\n",
        "\n",
        "    one_h_encod = np.zeros((len(corpus),len(words_set)))\n",
        "\n",
        "    tf_ = np.zeros((len(corpus),len(words_set)))\n",
        "\n",
        "    words_list = list(words_set)\n",
        "\n",
        "\n",
        "    for q in range(0,len(corpus)):\n",
        "\n",
        "\n",
        "        words_  = list(corpus[q].split(\" \"))\n",
        "\n",
        "        for h in words_:\n",
        "\n",
        "            one_h_encod [q][words_list.index(h)] = 1\n",
        "            tf_[q][words_list.index(h)] = tf_[q][words_list.index(h)] + 1\n",
        "\n",
        "    return pd.DataFrame(one_h_encod,columns = words_list) , pd.DataFrame(tf_ , columns = words_list)"
      ],
      "metadata": {
        "id": "Oabwb_Yzrwuh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TEACHER'S SIMILARITY"
      ],
      "metadata": {
        "id": "WmKiJl0VvBnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_lemmatization(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]"
      ],
      "metadata": {
        "id": "cIQAQkattYk1"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_processed_text(document):\n",
        "    # 1 - reduce el texto a mínuscula\n",
        "    # 2 - quitar los simbolos de puntuacion\n",
        "    # 3 - realiza la tokenización\n",
        "    # 4 - realiza la lematización\n",
        "    return perform_lemmatization(nltk.word_tokenize(document.lower().translate(punctuation_removal)))"
      ],
      "metadata": {
        "id": "_z7Dpzw6tGea"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(user_input, corpus):\n",
        "    response = ''\n",
        "    # Sumar al corpus la pregunta del usuario para calcular\n",
        "    # su cercania con otros documentos/sentencias\n",
        "\n",
        "    corpus.append(user_input)\n",
        "    df_ohe, df_tf = one_hot_encoding(corpus)\n",
        "\n",
        "    ####### IDF #######\n",
        "\n",
        "    idf = np.log10(len(corpus) / df_ohe.sum(axis= 0 ))\n",
        "\n",
        "    df_idf = pd.DataFrame(idf).T\n",
        "\n",
        "    ####### IDF #######\n",
        "\n",
        "    ####### TF_IDF #######\n",
        "\n",
        "    tf_idf = df_tf.copy()\n",
        "\n",
        "    cont = 0\n",
        "\n",
        "    for j in df_tf.columns:\n",
        "\n",
        "      tf_idf[j] = df_tf[j]*idf[cont]\n",
        "      cont = cont + 1\n",
        "\n",
        "    ####### TF_IDF #######\n",
        "\n",
        "\n",
        "    ####### COSINE SIMILARITY #######\n",
        "\n",
        "    cosine_m = np.zeros((len(corpus),len(corpus)))\n",
        "\n",
        "    similitud = 0\n",
        "    mayor = 0\n",
        "    response = \" \"\n",
        "    for t in range(len(corpus)):\n",
        "\n",
        "        a = np.array(tf_idf.iloc[t])\n",
        "        b = np.array(tf_idf.iloc[-1])\n",
        "\n",
        "        similitud =  (cosine_similarity(a,b))\n",
        "        if similitud >= mayor:\n",
        "          if user_input != corpus[t]:\n",
        "            mayor = similitud\n",
        "            response = corpus[t]\n",
        "\n",
        "\n",
        "    ####### COSINE SIMILARITY #######\n",
        "\n",
        "\n",
        "    return response"
      ],
      "metadata": {
        "id": "yZI6eVFXsFqZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "punctuation_removal = dict((ord(punctuation), None) for punctuation in string.punctuation)\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download('omw-1.4')\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "UxiQoFAktl2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbf33861-f7c7-4ac6-e1f2-83c6fc6574ae"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##TOPICS:\n",
        "* HOT DOG\n",
        "* FAST FOOD\n",
        "* COCA COLA\n",
        "* FOOD\n",
        "* OBESITY\n",
        "* OVERWEIGHT\n",
        "* SEDENTARY LIFESTYLE\n",
        "\n",
        "##WE ONLY SELECT 3 TOPICS RANDOMLY, IT CHANGES IN EACH EXECUTION"
      ],
      "metadata": {
        "id": "KtvZ6Ii5zl3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topics = [\"https://en.wikipedia.org/wiki/Hot_dog\",\"https://en.wikipedia.org/wiki/Fast_food\",\"https://en.wikipedia.org/wiki/Coca-Cola\",\"https://en.wikipedia.org/wiki/Food\",\"https://en.wikipedia.org/wiki/Obesity\",\"https://en.wikipedia.org/wiki/Overweight\",\"https://en.wikipedia.org/wiki/Sedentary_lifestyle\"]\n",
        "\n",
        "topics = random.sample(topics, 3)\n",
        "\n",
        "\n",
        "full_article = \"\"\n",
        "\n",
        "for i in topics:\n",
        "  raw_html = urllib.request.urlopen(i)\n",
        "  raw_html = raw_html.read()\n",
        "\n",
        "  article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "\n",
        "  article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "  article_text = ''\n",
        "\n",
        "  for para in article_paragraphs:\n",
        "      article_text += para.text\n",
        "\n",
        "  article_text = article_text.lower()\n",
        "  full_article = full_article + article_text"
      ],
      "metadata": {
        "id": "Tgp6_YH2nUix"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Topics used in for prediction: {}\".format(topics))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4clmCUA2jbL",
        "outputId": "fefd3ca1-2d25-47b8-acf1-bb30972c0394"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topics used in for prediction: ['https://en.wikipedia.org/wiki/Sedentary_lifestyle', 'https://en.wikipedia.org/wiki/Coca-Cola', 'https://en.wikipedia.org/wiki/Obesity']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = re.sub(r'\\[[0-9]*\\]', ' ', full_article)\n",
        "text = re.sub(r'\\s+', ' ', text)"
      ],
      "metadata": {
        "id": "dbu5CCKanXXc"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = nltk.sent_tokenize(text)\n",
        "words = nltk.word_tokenize(text)"
      ],
      "metadata": {
        "id": "y1HfnBQXnZsO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import gradio as gr\n",
        "\n",
        "!{sys.executable} -m pip install gradio --quiet\n",
        "\n",
        "\n",
        "def bot_response(human_text):\n",
        "    print(\"Q:\", human_text)\n",
        "    resp = generate_response(human_text.lower(), corpus)\n",
        "    print(\"A:\", resp)\n",
        "    return resp\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=bot_response,\n",
        "    inputs=[\"textbox\"],\n",
        "    outputs=\"text\",\n",
        "    layout=\"vertical\")\n",
        "\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720
        },
        "id": "ZNfAYyBpjxvN",
        "outputId": "422a8568-09da-48b0-fc6d-65d67ede6fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-d295e4518e0d>:13: GradioDeprecationWarning: `layout` parameter is deprecated, and it has no effect\n",
            "  iface = gr.Interface(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q: cocacola\n",
            "A: the risk of obesity in dogs is related to whether or not their owners are obese; however, there is no similar correlation between cats and their owners.\n",
            "Q: when coca-cola was created\n",
            "A: the advertisement was created by us advertising agency doner, and has been part of the company's global advertising campaign for many years.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topics"
      ],
      "metadata": {
        "id": "1Tojq_m12UDc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}