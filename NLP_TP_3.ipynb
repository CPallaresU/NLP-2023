{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BuYbwms2mnkB"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import string\n",
        "import random\n",
        "import re\n",
        "import urllib.request\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "# Para leer y parsear el texto en HTML de wikipedia\n",
        "import bs4 as bs\n",
        "import nltk\n",
        "# Descargar el diccionario\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import sys\n",
        "#import gradio as gr\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8_PieaU7r0DC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95744897-9213-433a-a91e-2221d2994ace"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!{sys.executable} -m pip install gradio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.callbacks import CallbackAny2Vec\n",
        "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
        "# Sobracargamos el callback para poder tener esta información\n",
        "class callback(CallbackAny2Vec):\n",
        "    \"\"\"\n",
        "    Callback to print loss after each epoch\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.epoch = 0\n",
        "\n",
        "    def on_epoch_end(self, model):\n",
        "        loss = model.get_latest_training_loss()\n",
        "        if self.epoch == 0:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
        "        else:\n",
        "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
        "        self.epoch += 1\n",
        "        self.loss_previous_step = loss"
      ],
      "metadata": {
        "id": "GX5inh72sgrF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cIQAQkattYk1"
      },
      "outputs": [],
      "source": [
        "def perform_lemmatization(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_z7Dpzw6tGea"
      },
      "outputs": [],
      "source": [
        "def get_processed_text(document):\n",
        "    # 1 - reduce el texto a mínuscula\n",
        "    # 2 - quitar los simbolos de puntuacion\n",
        "    # 3 - realiza la tokenización\n",
        "    # 4 - realiza la lematización\n",
        "    return perform_lemmatization(nltk.word_tokenize(document.lower().translate(punctuation_removal)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxiQoFAktl2b",
        "outputId": "a37365cb-57be-4fdd-a50c-7a029aae3d41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "punctuation_removal = dict((ord(punctuation), None) for punctuation in string.punctuation)\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download('omw-1.4')\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtvZ6Ii5zl3f"
      },
      "source": [
        "##TOPICS:\n",
        "* HOT DOG\n",
        "* FAST FOOD\n",
        "* COCA COLA\n",
        "* FOOD\n",
        "* OBESITY\n",
        "* OVERWEIGHT\n",
        "* SEDENTARY LIFESTYLE\n",
        "\n",
        "##WE ONLY SELECT 3 TOPICS RANDOMLY, IT CHANGES IN EACH EXECUTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Tgp6_YH2nUix"
      },
      "outputs": [],
      "source": [
        "topics = [\"https://en.wikipedia.org/wiki/Hot_dog\",\"https://en.wikipedia.org/wiki/Fast_food\",\"https://en.wikipedia.org/wiki/Coca-Cola\",\"https://en.wikipedia.org/wiki/Food\",\"https://en.wikipedia.org/wiki/Obesity\",\"https://en.wikipedia.org/wiki/Overweight\",\"https://en.wikipedia.org/wiki/Sedentary_lifestyle\"]\n",
        "\n",
        "full_article = \"\"\n",
        "\n",
        "for i in topics:\n",
        "  raw_html = urllib.request.urlopen(i)\n",
        "  raw_html = raw_html.read()\n",
        "\n",
        "  article_html = bs.BeautifulSoup(raw_html, 'lxml')\n",
        "\n",
        "  article_paragraphs = article_html.find_all('p')\n",
        "\n",
        "  article_text = ''\n",
        "\n",
        "  for para in article_paragraphs:\n",
        "      article_text += para.text\n",
        "\n",
        "  article_text = article_text.lower()\n",
        "  full_article = full_article + article_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "dbu5CCKanXXc"
      },
      "outputs": [],
      "source": [
        "text = re.sub(r'\\[[0-9]*\\]', ' ', full_article)\n",
        "text = re.sub(r'\\s+', ' ', text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "y1HfnBQXnZsO"
      },
      "outputs": [],
      "source": [
        "corpus = nltk.sent_tokenize(text)\n",
        "words = nltk.word_tokenize(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "option = 0"
      ],
      "metadata": {
        "id": "2dukMz0GvqA6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_1 = [s.split() for s in corpus]\n",
        "\n",
        "corpus_2 = []\n",
        "for t in corpus:\n",
        "    corpus_2.append(text_to_word_sequence(t))"
      ],
      "metadata": {
        "id": "Fvn2B93B2rPp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crearmos el modelo generador de vectoeres\n",
        "\n",
        "w2v_model_1 = Word2Vec(\n",
        "                     min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                     window=2,       # cant de palabras antes y desp de la predicha\n",
        "                     vector_size=300,       # dimensionalidad de los vectores\n",
        "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                     workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=0)           # modelo 0:CBOW  1:skipgram\n",
        "\n",
        "\n",
        "w2v_model_2 = Word2Vec(\n",
        "                     min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
        "                     window=2,       # cant de palabras antes y desp de la predicha\n",
        "                     vector_size=300,       # dimensionalidad de los vectores\n",
        "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
        "                     workers=1,      # si tienen más cores pueden cambiar este valor\n",
        "                     sg=0)           # modelo 0:CBOW  1:skipgram"
      ],
      "metadata": {
        "id": "qWO4R-C-r6Wi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model_1.build_vocab(corpus_1)\n",
        "w2v_model_2.build_vocab(corpus_2)"
      ],
      "metadata": {
        "id": "ajYiPgL0sobB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Cantidad de docs en el corpus:\", w2v_model_1.corpus_count)\n",
        "print(\"Cantidad de docs en el corpus:\", w2v_model_2.corpus_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvojO6STstIA",
        "outputId": "6de743f1-2576-42f4-fcf6-423dbb8ce8c5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cantidad de docs en el corpus: 1188\n",
            "Cantidad de docs en el corpus: 1188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo generador de vectores\n",
        "# Utilizamos nuestro callback\n",
        "w2v_model_1.train(corpus,\n",
        "                 total_examples=w2v_model_1.corpus_count,\n",
        "                 epochs=20,\n",
        "                 compute_loss = True,\n",
        "                 callbacks=[callback()]\n",
        "                 )\n",
        "\n",
        "w2v_model_2.train(corpus,\n",
        "                 total_examples=w2v_model_2.corpus_count,\n",
        "                 epochs=20,\n",
        "                 compute_loss = True,\n",
        "                 callbacks=[callback()]\n",
        "                 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FbB6vu3sxQu",
        "outputId": "b5330662-22ec-4021-dd2f-60b59df63c99"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0: 12209.306640625\n",
            "Loss after epoch 1: 5655.638671875\n",
            "Loss after epoch 2: 5653.0703125\n",
            "Loss after epoch 3: 5229.556640625\n",
            "Loss after epoch 4: 4999.955078125\n",
            "Loss after epoch 5: 5290.69140625\n",
            "Loss after epoch 6: 5276.94140625\n",
            "Loss after epoch 7: 5086.84765625\n",
            "Loss after epoch 8: 4857.09375\n",
            "Loss after epoch 9: 5356.12109375\n",
            "Loss after epoch 10: 5142.3359375\n",
            "Loss after epoch 11: 5086.58984375\n",
            "Loss after epoch 12: 5187.3203125\n",
            "Loss after epoch 13: 4556.4453125\n",
            "Loss after epoch 14: 5044.78125\n",
            "Loss after epoch 15: 5073.96875\n",
            "Loss after epoch 16: 4744.53125\n",
            "Loss after epoch 17: 4442.6953125\n",
            "Loss after epoch 18: 4969.6171875\n",
            "Loss after epoch 19: 4626.359375\n",
            "Loss after epoch 0: 48303.71484375\n",
            "Loss after epoch 1: 31027.69140625\n",
            "Loss after epoch 2: 29698.7890625\n",
            "Loss after epoch 3: 29268.1015625\n",
            "Loss after epoch 4: 29241.984375\n",
            "Loss after epoch 5: 28694.109375\n",
            "Loss after epoch 6: 28768.125\n",
            "Loss after epoch 7: 28522.4375\n",
            "Loss after epoch 8: 28658.703125\n",
            "Loss after epoch 9: 28395.125\n",
            "Loss after epoch 10: 28232.78125\n",
            "Loss after epoch 11: 28357.0\n",
            "Loss after epoch 12: 28078.34375\n",
            "Loss after epoch 13: 28201.375\n",
            "Loss after epoch 14: 28367.53125\n",
            "Loss after epoch 15: 28211.375\n",
            "Loss after epoch 16: 28031.84375\n",
            "Loss after epoch 17: 27699.59375\n",
            "Loss after epoch 18: 27424.375\n",
            "Loss after epoch 19: 27634.5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1304508, 3408000)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##APARCIÓN DEL BMI, BODY MASS INDEX"
      ],
      "metadata": {
        "id": "IzWyWLRN5e8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_p = [\"healthy\"]"
      ],
      "metadata": {
        "id": "n_d7Pfkm4AgW"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model_1.wv.most_similar(positive=word_p,topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI4MLcK73NZ1",
        "outputId": "a440dd2b-62e4-4d6e-da95-d75e9c648518"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('group', 0.1414330005645752),\n",
              " ('held', 0.1382761001586914),\n",
              " ('consumers', 0.13777770102024078),\n",
              " ('class', 0.13561250269412994),\n",
              " ('thus', 0.13519111275672913),\n",
              " ('children.', 0.13360245525836945),\n",
              " ('rate', 0.1331871896982193),\n",
              " ('advertisements', 0.1307992786169052),\n",
              " ('company,', 0.12945395708084106),\n",
              " ('received', 0.1279081404209137)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w2v_model_2.wv.most_similar(positive=word_p,topn=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQZdGK22s3Gq",
        "outputId": "79c50916-6b40-4ef4-80f8-db1069085c1a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('significantly', 0.18254433572292328),\n",
              " ('negative', 0.16583077609539032),\n",
              " ('known', 0.15238207578659058),\n",
              " ('treatments', 0.1516413539648056),\n",
              " ('served', 0.1463031768798828),\n",
              " ('if', 0.14583048224449158),\n",
              " ('000', 0.14335739612579346),\n",
              " ('contains', 0.14265966415405273),\n",
              " ('nuts', 0.1391775757074356),\n",
              " ('syndrome', 0.13550493121147156)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import IncrementalPCA\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "\n",
        "def reduce_dimensions(model):\n",
        "    num_dimensions = 2\n",
        "\n",
        "    vectors = np.asarray(model.wv.vectors)\n",
        "    labels = np.asarray(model.wv.index_to_key)\n",
        "\n",
        "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
        "    vectors = tsne.fit_transform(vectors)\n",
        "\n",
        "    x_vals = [v[0] for v in vectors]\n",
        "    y_vals = [v[1] for v in vectors]\n",
        "    return x_vals, y_vals, labels"
      ],
      "metadata": {
        "id": "-aMbRUmWD6nb"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar los embedddings en 2D\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "x_vals, y_vals, labels = reduce_dimensions(w2v_model_1)\n",
        "\n",
        "MAX_WORDS=200\n",
        "fig = px.scatter(x=x_vals[:MAX_WORDS], y=y_vals[:MAX_WORDS], text=labels[:MAX_WORDS])\n",
        "fig.show(renderer=\"colab\") # esto para plotly en colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "Sjao8MLPEA5S",
        "outputId": "7aa661db-dbc9-42fb-b17f-ae2513349878"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.18.2.min.js\"></script>                <div id=\"8d969d74-6643-4216-b47a-ae7b8c67abea\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8d969d74-6643-4216-b47a-ae7b8c67abea\")) {                    Plotly.newPlot(                        \"8d969d74-6643-4216-b47a-ae7b8c67abea\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<br>text=%{text}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers+text\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"text\":[\"the\",\"in\",\"and\",\"of\",\"to\",\"a\",\"is\",\"as\",\"for\",\"are\",\"with\",\"coca-cola\",\"that\",\"on\",\"by\",\"was\",\"food\",\"or\",\"from\",\"obesity\",\"have\",\"be\",\"it\",\"hot\",\"has\",\"at\",\"an\",\"this\",\"more\",\"their\",\"than\",\"which\",\"fast\",\"its\",\"been\",\"also\",\"were\",\"company\",\"some\",\"weight\",\"not\",\"health\",\"people\",\"such\",\"most\",\"one\",\"dog\",\"can\",\"other\",\"they\",\"found\",\"bmi\",\"many\",\"may\",\"obese\",\"risk\",\"these\",\"united\",\"dogs\",\"while\",\"between\",\"who\",\"overweight\",\"obesity.\",\"used\",\"had\",\"over\",\"physical\",\"body\",\"increased\",\"but\",\"fat\",\"first\",\"due\",\"energy\",\"there\",\"during\",\"world\",\"new\",\"when\",\"however,\",\"all\",\"time\",\"being\",\"his\",\"those\",\"among\",\"children\",\"increase\",\"use\",\"after\",\"restaurants\",\"rates\",\"two\",\"made\",\"about\",\"often\",\"common\",\"drink\",\"into\",\"coke\",\"high\",\"include\",\"per\",\"american\",\"only\",\"served\",\"states\",\"both\",\"us\",\"including\",\"sold\",\"he\",\"same\",\"known\",\"because\",\"candler\",\"no\",\"considered\",\"diet\",\"billion\",\"sedentary\",\"popular\",\"since\",\"less\",\"average\",\"increasing\",\"fast-food\",\"would\",\"social\",\"then\",\"advertising\",\"name\",\"foods\",\"through\",\"bottle\",\"sausage\",\"activity\",\"medical\",\"like\",\"lifestyle\",\"study\",\"consumption\",\"if\",\"associated\",\"research\",\"up\",\"dietary\",\"where\",\"meat\",\"cause\",\"commercial\",\"pemberton's\",\"changes\",\"could\",\"effects\",\"several\",\"became\",\"greater\",\"called\",\"world.\",\"type\",\"market\",\"local\",\"formula\",\"much\",\"25\",\"healthy\",\"although\",\"countries\",\"increases\",\"bottles\",\"source\",\"national\",\"term\",\"age\",\"well\",\"sitting\",\"significant\",\"products\",\"reduce\",\"eating\",\"–\",\"middle\",\"under\",\"compared\",\"years\",\"low\",\"around\",\"even\",\"early\",\"types\",\"heart\",\"adults\",\"association\",\"factors\",\"plant\",\"global\",\"person\",\"amount\"],\"x\":[13.964525,-12.09856,-3.1695864,6.0001907,-21.88039,-20.931108,-3.3273597,-1.172822,1.2821681,21.332546,4.8956194,18.83143,0.5099155,-14.362716,-1.7876861,3.3193655,15.750283,8.426268,6.925635,-12.698437,15.714051,-13.182745,14.157335,0.48230612,-12.191493,-8.358023,-1.9005206,13.312843,-2.0062373,-6.2874537,11.866187,7.4439783,-8.968563,-15.817452,-3.791395,16.607847,0.88821876,11.354115,1.748432,-10.6653385,5.825069,18.334465,-16.92139,9.1065035,-6.7471066,6.828897,-13.995876,10.618141,14.58809,-7.6040735,8.26426,-13.953555,18.940763,-4.2904034,6.4242034,-5.1241097,-1.5698956,0.0028206264,13.941337,-2.7061117,-4.3440866,-12.850518,-6.889161,10.013993,-20.399288,3.4203312,3.3221536,-5.127633,-2.7128856,0.58951277,-11.149316,11.620876,5.81618,7.311831,-5.469117,11.088176,10.660787,-14.920369,13.734718,19.219234,4.27404,6.411361,12.038091,-8.345555,4.8150344,-21.485807,9.013597,-10.433546,9.345069,1.5909129,-8.592938,-14.171691,6.3711243,-10.660861,-14.460822,2.4788299,2.6566825,3.7805285,-7.3166156,5.1463876,-6.316393,-11.029586,6.6607466,5.5247436,-14.358657,-10.995442,5.78327,7.708462,6.10995,5.012966,-3.623297,-7.137344,-6.160141,-2.8627448,4.994193,-15.89222,-3.8444264,7.800475,11.971217,-0.73761624,9.303191,-7.9604826,-5.3646517,-3.2508752,-3.9525063,-10.019055,22.121117,-5.53201,4.4790044,0.26715833,-4.4596896,7.281319,-0.7638797,13.595955,-8.775927,10.065,7.413886,-17.660017,-9.869608,-4.65098,13.679878,5.878549,-1.1172831,3.5956652,8.90409,7.1795254,11.863692,-21.702791,9.200929,2.2013295,1.5626757,3.2991097,3.8652427,1.2561841,11.762661,-12.938861,-0.53984976,-4.8700113,-8.861107,2.5305047,1.1555489,-0.9513618,-14.945253,-8.781823,-1.0284011,0.7026545,-5.192239,-1.2779956,-3.7322526,-10.975737,20.23528,-0.6353869,0.2819455,-10.078201,-11.212771,-0.85870403,-10.031963,1.0431998,-7.1322722,4.8979373,-8.7630205,-6.4044495,-20.529377,-1.2926803,-2.985879,7.940612,-5.9476695,3.394552,-10.679058,-20.479197,-16.223202,-15.05603,-8.022876,4.8821287,17.069904,15.831591,10.977125,-11.480171,14.607347,13.079743],\"xaxis\":\"x\",\"y\":[11.1290455,1.7252678,12.2594795,-1.1887817,5.030082,17.802525,10.562006,11.81085,-19.318045,-0.1804204,-10.787431,3.2863748,2.9085488,14.254063,14.6324625,-14.812104,-16.347195,1.6152936,21.690231,-9.372682,-16.344652,-0.7727729,11.75537,7.709341,13.696281,13.063244,4.462871,6.563211,-8.179605,5.8904104,0.49118942,6.211937,-13.359034,7.628744,21.552263,-12.074903,-0.6728742,-2.5180337,8.086882,-11.690235,-3.8413289,7.34027,-13.915854,-14.168829,-10.428733,-5.606171,-4.630311,7.3019133,3.2050645,17.285845,3.3429945,-0.7301783,7.939886,7.953823,-14.157344,-0.04203948,-14.937949,-11.008333,10.965436,-6.156846,16.32935,-5.244756,-2.3112266,4.6557794,8.608069,-8.884647,-16.056213,20.767721,-10.536708,-10.919085,-20.371006,-15.836397,2.2949357,2.1047773,-11.9609375,-7.7084694,2.565358,-0.6573663,1.9490803,-3.5455065,-2.854704,-22.23082,-2.5477052,-7.5127177,4.440298,-8.57744,8.964186,11.702628,-6.6363063,23.852802,-4.611853,0.47789362,-22.192617,19.732721,-5.8261237,13.158524,4.5111823,-20.519232,-14.821641,-8.77246,3.2371254,8.541759,7.8830748,3.5601504,5.35477,-8.805066,-13.958851,20.996994,1.5351115,7.1937613,4.86522,-12.919661,-0.7683093,10.906221,-8.005841,1.1251792,13.515362,14.342556,1.491636,-12.95703,-1.3869436,17.900482,-9.080903,3.6704617,14.932003,6.6863375,-7.124327,4.006926,-18.922184,-13.297141,-7.054071,-11.583673,18.764925,-4.6248407,-6.8190684,-17.723835,4.5385895,11.442555,-16.211458,-2.2859719,-4.3711824,11.738596,-9.573779,15.89083,11.245449,-13.740366,-8.439343,-0.018093446,-6.811652,-5.0487485,3.11252,-1.8186306,12.696981,0.97372955,-5.1130195,-7.871567,-3.105731,-9.778313,-2.833271,-8.63343,-1.8465143,-7.980744,11.446962,8.869755,11.721837,12.569214,-7.5068474,21.040142,0.6309186,-13.489412,-7.2052746,-19.514565,-9.003305,-11.462581,2.9138086,-3.1613889,-16.358847,1.5639973,-18.93789,2.894397,5.529725,-4.110164,17.748957,-1.2515734,6.911514,20.776642,13.494253,5.200656,10.6310835,-8.55053,7.632687,14.571483,11.865995,3.0415668,10.37766,6.180097,-4.723925,-3.2511578,-1.0626942,-11.678673],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"x\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8d969d74-6643-4216-b47a-ae7b8c67abea');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Para 0<Y<10 y, -10<X<-5 vemos que fast, food y coke están agrupados, claramente existe relación, podemos relacionar coke(Coca-Cola) con food o fast food\n",
        "\n",
        "* Para -13<Y<-10 y, -11<X<-10 vemos que national y countries tienen cercania, como weight, medical y fast\n",
        "\n",
        "*  Para -5<Y<-4 y, 13.5<X<14 tenemos lifestyle y foods, claramente relación entre ambas palabras\n",
        "\n",
        "El modelo genera relaciones entre palabras claves mas recurrentes que otras, a diferencia de stop words o palabras complementarias de una oración"
      ],
      "metadata": {
        "id": "eq77ZiIVHGVB"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}